{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "293b69a7-3b84-4b7c-9c1d-18849ef473c9",
   "metadata": {},
   "source": [
    "# Toy Medical Question Answering GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aa694e-b7b3-4e59-abac-582319be41a2",
   "metadata": {},
   "source": [
    "In this exercise, we will utilize the MinGPT library to train a basic medical Question and Answer (Q&A) model from scratch. Our goal is to create a model that can provide answers to medical-related questions using the MedQA dataset. While our resulting model may not reach the precision required for clinical use, this exercise will serve as a valuable hands-on experience in understanding the training process of Q&A models and the nuances of handling domain-specific data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093ee937-f65f-4ef7-b175-2fffc165b371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_dataset_builder, get_dataset_split_names\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from mingpt.bpe import BPETokenizer\n",
    "from mingpt.model import GPT\n",
    "from mingpt.trainer import Trainer\n",
    "\n",
    "import torch\n",
    "\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cd21b5-5e65-4c44-89c3-e6a3815ec3cb",
   "metadata": {},
   "source": [
    "## 1. MedQA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df1c9d-6136-4b77-9589-f13b360c1811",
   "metadata": {},
   "source": [
    "The MedQA dataset, introduced in the paper by Jin et al. in 2021, is a comprehensive dataset formulated for the task of medical question answering. It consists of question-and-answer pairs derived from a variety of medical examinations and literature, providing a robust foundation for training models intended for medical information retrieval and Q&A tasks. The dataset encompasses a broad spectrum of medical knowledge, making it an excellent resource for training specialized models in the medical domain. Its structured format facilitates the training of models capable of interpreting medical queries and providing accurate, informative responses.\n",
    "\n",
    "Jin, Q., Dhingra, B., Liu, Z., Cohen, W., & Lu, X. (2021). Disease Knowledge Distillation for Medical Dialogue Generation.  [Link to Paper](https://arxiv.org/abs/2109.00704)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c33e4-d23b-44ee-a8f0-3ece5aa34489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will use Huggingface datasets to get our working version\n",
    "\n",
    "DATASET_NAME = \"bigbio/med_qa\"\n",
    "DATASET_CONFIG = \"med_qa_en_source\"\n",
    "ds_builder = load_dataset_builder(DATASET_NAME,DATASET_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bcd705-f928-4b5a-84b3-f7775b4067e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the summary \n",
    "print(ds_builder.info.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a06609-a5cd-40f1-a36e-0977e58c9c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = load_dataset(DATASET_NAME, DATASET_CONFIG, split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52ee871-9ece-4d5b-96e7-e13a27697433",
   "metadata": {},
   "source": [
    "Let's look at a couple of examples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74da13-7dab-46b6-bbb5-b8f9a1ca8547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "\n",
    "sample = train_ds[idx]\n",
    "print(f\"\"\"Sample {idx}:\n",
    "\n",
    "Question:\n",
    "{sample['question']}\n",
    "\n",
    "Answer:\n",
    "{sample['answer']}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48607ca8-3c03-4942-aa1e-3a20458f3afc",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f84cce1-f88a-4383-bca9-91474adfb908",
   "metadata": {},
   "source": [
    "In order to feed the text into the GPT model, we must first tokenize the input (converting the text into a series of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d705118-7984-4bac-864c-23976355e1c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the tokenizer\n",
    "\n",
    "bpe_tokenizer = BPETokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dae492-65f2-4bed-a14a-a17f59e8989d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize the sample question\n",
    "\n",
    "bpe_tokenizer(train_ds[idx]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12118bd-a9ef-4735-9be5-ab153cc74bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's look at a how these map with each other\n",
    "results = bpe_tokenizer.encoder.encode_and_show_work(train_ds[0]['question'])\n",
    "# print(train_ds[0]['question'])\n",
    "print(\"ID\\t|\\tTOKEN\")\n",
    "print(\"------------------\")\n",
    "for token, bpe_id in zip(results['tokens'], results['bpe_idx']):\n",
    "    print(f\"{bpe_id}\\t|\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9105b35-b65b-44ca-84e2-03005d89e021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will use this function to encode each sample into a string\n",
    "# Our model will learn to predict the most likely answer string\n",
    "# conditioned on the input question\n",
    "\n",
    "def encode_examples(example):\n",
    "    training_sentence = f\"\"\"{example['question']}\n",
    "    \n",
    "    Answer: {example['answer']}\n",
    "    \"\"\"\n",
    "    return bpe_tokenizer(training_sentence)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdab74b-cd96-4b22-9902-03c49d951927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Each of our samples are different lengths\n",
    "# For simplicity, we will limit our samples to only those longer than 129 tokens\n",
    "# We will also the beginning of each example to be only 129 tokens long\n",
    "\n",
    "tokenizer_examples = [encode_examples(ex) for ex in train_ds]\n",
    "\n",
    "# I only want to keep examples longer than 128 tokens\n",
    "# I only want to use the last 129 tokens of each example\n",
    "tokenized_train = [ex[-129:] for ex in tokenizer_examples if len(ex) >= 129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ce216-7355-4cdc-846b-bb2105c94685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is an idiomatic torch map style dataset wrapper around our data\n",
    "\n",
    "class SimpleMedQADataset(Dataset):\n",
    "    def __init__(self, tokenized_examples):\n",
    "        self.tokenized_examples = tokenized_examples\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_examples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokenized_examples[idx][:-1], self.tokenized_examples[idx][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6738c2-942c-45b1-b0c1-1e8f4a3ed677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = SimpleMedQADataset(tokenized_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b78a2c-9cbd-4696-9e66-7a9ece4c932f",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d304f-63e7-48d3-a0d3-66408672129f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just like in the last exercise, we first put our model's hyperparameters\n",
    "# in a config - we will train a medium sized GPT2 from scratch\n",
    "\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.model_type = 'gpt2'\n",
    "model_config.vocab_size = 50257\n",
    "model_config.block_size = 256\n",
    "model = GPT(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2077549-07e7-4d11-8063-b69080a0a215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here we will use the built-in trainer class of the minGPT library encapsulate our training loop\n",
    "\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 5e-4 # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 2000\n",
    "train_config.num_workers = 0\n",
    "trainer = Trainer(train_config, model, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282c1305-1d8b-4788-8417-41f207f3e758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here we provide a callback to occasionally log our training progress to output\n",
    "\n",
    "def batch_end_callback(trainer):\n",
    "    if trainer.iter_num % 10 == 0:\n",
    "        print(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
    "\n",
    "# Add the callback to be called at the end of each batch        \n",
    "trainer.set_callback('on_batch_end', batch_end_callback)\n",
    "\n",
    "# Here we start the trainer\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3325fdf5-013c-4845-a056-db123e52c4ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This will take a while to get to reasonable loss - we will come back after a while to check in on this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda3e343-5489-4689-a0fa-433a94d9ba7e",
   "metadata": {},
   "source": [
    "# 4. Check Model Generation Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e293f7-0a4c-4398-b339-1f060a246c66",
   "metadata": {},
   "source": [
    "**DISCLAIMER:** We have trained a small, toy model from scratch(!) on a relatively small dataset (9K examples) so DO NOT use this model for any diagnostic purposes!  This exercise is only intended to demonstrate how to use PyTorch directly for training a model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02a3f32-e0b8-4198-8252-3b1840b80200",
   "metadata": {},
   "source": [
    "Given the small model and dataset, we should not expect a model with particularly strong performance on this complex, knowledge-intensive clinical reasoning dataset.\n",
    "\n",
    "What is reasonable to see though is \"medically flavored\" nonsense.  We should see strings of words that kind of look medical or clinical.  Perhaps certain phrases may appear.  However, there is very little in the way of logical though process.\n",
    "\n",
    "Larger models with more training data are able to accomplish this mimicry with much greater fidelity.  At the end of the day however they share the same fundamental architecture as this model and most of the same training recipe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51584155-f5fb-42e2-a05d-14f1e6755bb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 200\n",
    "\n",
    "inputs = bpe_tokenizer(train_ds[idx]['question']+\"\\n\\nAnswer:\").to(device)\n",
    "outputs = model.generate(inputs, max_new_tokens=20, top_k=100)\n",
    "\n",
    "try:\n",
    "    offset = list(outputs[0][-20:]).index(198)\n",
    "except:\n",
    "    offset = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcceb9bb-e863-4ee5-be4b-858c5583bbc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_ds[idx]['question'])\n",
    "bpe_tokenizer.decode(outputs[0][len(inputs[0]):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6f7854-84fd-47f4-9424-c8089d1f53ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds[idx]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c9b9a-6f98-4307-928f-139dfb7e1891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
