{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ref: https://github.com/phlippe/uvadlc_notebooks - a great resource for all things PyTorch and Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpCNz5j2lvLk",
    "outputId": "42ad6698-2a4b-40c0-9f25-284847972258",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgba\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7E7WlOllvLl"
   },
   "source": [
    "## The Basics of PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CoCVtKF_lvLl",
    "outputId": "a2213063-4fe0-4d11-c8a6-57708b496511",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"Using torch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_3iboLKlvLl",
    "outputId": "fa91da0b-b553-4fdd-ad41-b453268eeaa4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42) # Setting the seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgnzB0j0lvLm"
   },
   "source": [
    "### Tensors\n",
    "\n",
    "Tensors are the PyTorch equivalent to Numpy arrays, with the addition to also have support for GPU acceleration (more on that later).\n",
    "Most common functions you know from numpy can be used on tensors as well.\n",
    "\n",
    "#### Initialization\n",
    "\n",
    "Let's first start by looking at different ways of creating a tensor. There are many possible options, the simplest one is to call `torch.Tensor` passing the desired shape as input argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0DtrvuilvLm",
    "outputId": "484fa0b7-7a0a-4000-f021-346854479ec7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.Tensor(2, 3, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D40ppT0ElvLm"
   },
   "source": [
    "The function `torch.Tensor` allocates memory for the desired tensor, but reuses any values that have already been in the memory. To directly assign values to the tensor during initialization, there are many alternatives including:\n",
    "\n",
    "* `torch.zeros`: Creates a tensor filled with zeros\n",
    "* `torch.ones`: Creates a tensor filled with ones\n",
    "* `torch.rand`: Creates a tensor with random values uniformly sampled between 0 and 1\n",
    "* `torch.randn`: Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
    "* `torch.arange`: Creates a tensor containing the values $N,N+1,N+2,...,M$\n",
    "* `torch.Tensor` (input list): Creates a tensor from the list elements you provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0Jn8a_slvLm",
    "outputId": "8202de39-1534-4036-e2a3-ff33f3980f1b"
   },
   "outputs": [],
   "source": [
    "# Create a tensor from a (nested) list\n",
    "x = torch.Tensor([[1, 2], [3, 4]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ulJ6x75ylvLm",
    "outputId": "ff194b56-d4e1-4473-dfe5-e35c0df5271b"
   },
   "outputs": [],
   "source": [
    "# Create a tensor with random values between 0 and 1 with the shape [2, 3, 4]\n",
    "x = torch.rand(2, 3, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-c1Xz2FlvLn"
   },
   "source": [
    "You can obtain the shape of a tensor in the same way as in numpy (`x.shape`), or using the `.size` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-4Q8-tVlvLn",
    "outputId": "5ec79af9-5d31-402f-dadf-1afa056d39f9"
   },
   "outputs": [],
   "source": [
    "shape = x.shape\n",
    "print(\"Shape:\", x.shape)\n",
    "\n",
    "size = x.size()\n",
    "print(\"Size:\", size)\n",
    "\n",
    "dim1, dim2, dim3 = x.size()\n",
    "print(\"Size:\", dim1, dim2, dim3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7ZYxEhglvLn"
   },
   "source": [
    "#### Tensor to Numpy, and Numpy to Tensor\n",
    "\n",
    "Tensors can be converted to numpy arrays, and numpy arrays back to tensors. To transform a numpy array into a tensor, we can use the function `torch.from_numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7AnSXkElvLn",
    "outputId": "bc5480ff-fb40-4ec2-fd17-416472271069"
   },
   "outputs": [],
   "source": [
    "np_arr = np.array([[1, 2], [3, 4]])\n",
    "tensor = torch.from_numpy(np_arr)\n",
    "\n",
    "print(\"Numpy array:\", np_arr)\n",
    "print(\"PyTorch tensor:\", tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJEgCteglvLn"
   },
   "source": [
    "To transform a PyTorch tensor back to a numpy array, we can use the function `.numpy()` on tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRE6PkPWlvLn",
    "outputId": "9a91ad5a-5366-4ea8-ee87-8ee193a9f9d2"
   },
   "outputs": [],
   "source": [
    "tensor = torch.arange(4)\n",
    "np_arr = tensor.numpy()\n",
    "\n",
    "print(\"PyTorch tensor:\", tensor)\n",
    "print(\"Numpy array:\", np_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIPvPRFklvLn"
   },
   "source": [
    "The conversion of tensors to numpy require the tensor to be on the CPU, and not the GPU (more on GPU support in a later section). In case you have a tensor on GPU, you need to call `.cpu()` on the tensor beforehand. Hence, you get a line like `np_arr = tensor.cpu().numpy()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbpbgNkAlvLn"
   },
   "source": [
    "#### Operations\n",
    "\n",
    "Most operations that exist in numpy, also exist in PyTorch. A full list of operations can be found in the [PyTorch documentation](https://pytorch.org/docs/stable/tensors.html#), but we will review the most important ones here.\n",
    "\n",
    "The simplest operation is to add two tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hlEeQdMlvLn",
    "outputId": "24ad7988-6c08-4890-9228-c6ab1dae443d"
   },
   "outputs": [],
   "source": [
    "x1 = torch.rand(2, 3)\n",
    "x2 = torch.rand(2, 3)\n",
    "y = x1 + x2\n",
    "\n",
    "# Atlernatively\n",
    "x2.add_(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RttPEMMlvLn"
   },
   "source": [
    "Calling `x1 + x2` creates a new tensor containing the sum of the two inputs. However, we can also use in-place operations that are applied directly on the memory of a tensor. We therefore change the values of `x2` without the chance to re-accessing the values of `x2` before the operation. An example is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVZmXpthlvLo"
   },
   "source": [
    "In-place operations are usually marked with a underscore postfix (e.g. \"add_\" instead of \"add\").\n",
    "\n",
    "Another common operation aims at changing the shape of a tensor. A tensor of size (2,3) can be re-organized to any other shape with the same number of elements (e.g. a tensor of size (6), or (3,2), ...). In PyTorch, this operation is called `view`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-vHFaUNjlvLo",
    "outputId": "bbbeddf2-2cbf-4cfd-ed3e-b130fb277a68"
   },
   "outputs": [],
   "source": [
    "x = torch.arange(6)\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qiUhPJClvLo",
    "outputId": "bce6bd01-043b-489d-d629-8d7a3ec3e001"
   },
   "outputs": [],
   "source": [
    "x = x.view(2, 3)\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGcIpo7plvLo",
    "outputId": "8a5d279a-d757-4a2b-b812-c6999f59e9b7"
   },
   "outputs": [],
   "source": [
    "x = x.permute(1, 0) # Swapping dimension 0 and 1\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQOUZAublvLo"
   },
   "source": [
    "Other commonly used operations include matrix multiplications, which are essential for neural networks. Quite often, we have an input vector $\\mathbf{x}$, which is transformed using a learned weight matrix $\\mathbf{W}$. There are multiple ways and functions to perform matrix multiplication, some of which we list below:\n",
    "\n",
    "* `torch.matmul`: Performs the matrix product over two tensors, where the specific behavior depends on the dimensions. If both inputs are matrices (2-dimensional tensors), it performs the standard matrix product. For higher dimensional inputs, the function supports broadcasting (for details see the [documentation](https://pytorch.org/docs/stable/generated/torch.matmul.html?highlight=matmul#torch.matmul)). Can also be written as `a @ b`, similar to numpy.\n",
    "* `torch.mm`: Performs the matrix product over two matrices, but doesn't support broadcasting (see [documentation](https://pytorch.org/docs/stable/generated/torch.mm.html?highlight=torch%20mm#torch.mm))\n",
    "* `torch.bmm`: Performs the matrix product with a support batch dimension. If the first tensor $T$ is of shape ($b\\times n\\times m$), and the second tensor $R$ ($b\\times m\\times p$), the output $O$ is of shape ($b\\times n\\times p$), and has been calculated by performing $b$ matrix multiplications of the submatrices of $T$ and $R$: $O_i = T_i @ R_i$\n",
    "* `torch.einsum`: Performs matrix multiplications and more (i.e. sums of products) using the Einstein summation convention. Explanation of the Einstein sum can be found in assignment 1.\n",
    "\n",
    "Usually, we use `torch.matmul` or `torch.bmm`. We can try a matrix multiplication with `torch.matmul` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EUqUzBvdlvLo",
    "outputId": "bacf402c-86e3-4545-a5b1-fe2ac556eff4"
   },
   "outputs": [],
   "source": [
    "x = torch.arange(6)\n",
    "x = x.view(2, 3)\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnlNCHQllvLo",
    "outputId": "aa960155-0af1-4fc8-ffe5-ce3c37d96279"
   },
   "outputs": [],
   "source": [
    "W = torch.arange(9).view(3, 3) # We can also stack multiple operations in a single line\n",
    "print(\"W\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PY4IQd95lvLo",
    "outputId": "bd7dcc15-d345-4e42-96e3-25f0708fd3f9"
   },
   "outputs": [],
   "source": [
    "h = torch.matmul(x, W) # Verify the result by calculating it by hand too!\n",
    "print(\"h\", h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWOKSrgJlvLo"
   },
   "source": [
    "#### Indexing\n",
    "\n",
    "We often have the situation where we need to select a part of a tensor. Indexing works just like in numpy, so let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nmjOZz8lvLo",
    "outputId": "e5ff43ce-2de2-487b-e3df-b76dd568b256"
   },
   "outputs": [],
   "source": [
    "x = torch.arange(12).view(3, 4)\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gU1aVmn5lvLo",
    "outputId": "ee2dd957-77d3-4c59-af34-7b6b7d8b15d7"
   },
   "outputs": [],
   "source": [
    "print(x[:, 1])   # Second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xKs3kkQlvLo",
    "outputId": "027f6625-0433-460c-8174-32c5f03651d9"
   },
   "outputs": [],
   "source": [
    "print(x[0])      # First row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqSsoKrPlvLo",
    "outputId": "00270737-254b-4a40-81b2-1cf81cf9f2ee"
   },
   "outputs": [],
   "source": [
    "print(x[:2, -1]) # First two rows, last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yeoPJcwAlvLo",
    "outputId": "3feaebb5-5684-48d9-b81c-22d7ca6546b9"
   },
   "outputs": [],
   "source": [
    "print(x[1:3, :]) # Middle two rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwLyIsYElvLp"
   },
   "source": [
    "### Dynamic Computation Graph and Backpropagation\n",
    "\n",
    "One of the main reasons for using PyTorch in Deep Learning projects is that we can automatically get **gradients/derivatives** of functions that we define.\n",
    "\n",
    "PyTorch is a **define-by-run** framework; this means that we can just do our manipulations, and PyTorch will keep track of that graph for us. Thus, we create a dynamic computation graph along the way.\n",
    "The only thing we have to do is to compute the **output**, and then we can ask PyTorch to automatically get the **gradients**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqopIHPIlvLp",
    "outputId": "c0ccaaa0-6a80-411b-bfbb-de6ec5879fe8"
   },
   "outputs": [],
   "source": [
    "x = torch.ones((3,))\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxr6orFClvLs"
   },
   "source": [
    "We can change this for an existing tensor using the function `requires_grad_()` (underscore indicating that this is a in-place operation). Alternatively, when creating a tensor, you can pass the argument `requires_grad=True` to most initializers we have seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7xD_r6xlvLs",
    "outputId": "e4547d9e-b9cd-4fcc-c98a-7e0945f91a43"
   },
   "outputs": [],
   "source": [
    "x.requires_grad_(True)\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0FxmdMUlvLs"
   },
   "source": [
    "In order to get familiar with the concept of a computation graph, we will create one for the following function:\n",
    "\n",
    "$$y = \\frac{1}{\\ell(x)}\\sum_i \\left[(x_i + 2)^2 + 3\\right],$$\n",
    "\n",
    "where we use $\\ell(x)$ to denote the number of elements in $x$. In other words, we are taking a mean here over the operation within the sum. You could imagine that $x$ are our parameters, and we want to optimize (either maximize or minimize) the output $y$. For this, we want to obtain the gradients $\\partial y / \\partial \\mathbf{x}$. For our example, we'll use $\\mathbf{x}=[0,1,2]$ as our input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5g15S45lvLs",
    "outputId": "390cdfb8-6a54-4628-bd1b-a14d7c623dce"
   },
   "outputs": [],
   "source": [
    "x = torch.arange(3, dtype=torch.float32, requires_grad=True) # Only float tensors can have gradients\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QhKLzmzlvLs"
   },
   "source": [
    "Now let's build the computation graph step by step. You can combine multiple operations in a single line, but we will separate them here to get a better understanding of how each operation is added to the computation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7vWV6solvLs",
    "outputId": "793db02a-78ce-4bd5-880f-0d5172fbd89a"
   },
   "outputs": [],
   "source": [
    "a = x + 2\n",
    "b = a ** 2\n",
    "c = b + 3\n",
    "y = c.mean()\n",
    "print(\"Y\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcVtsW_zlvLt"
   },
   "source": [
    "Using the statements above, we have created a computation graph that looks similar to the figure below:\n",
    "\n",
    "<center style=\"width: 100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/pytorch_computation_graph.svg?raw=1\" width=\"200px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform backpropagation on the computation graph by calling the function `backward()` on the last output, which effectively calculates the gradients for each tensor that has the property `requires_grad=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xzubi33vlvLt"
   },
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxmfRV7ylvLt"
   },
   "source": [
    "`x.grad` will now contain the gradient $\\partial y/ \\partial \\mathcal{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oc8kst_flvLt",
    "outputId": "f3952ab1-4091-4e01-b764-b51e6862545c"
   },
   "outputs": [],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUZ520PClvLt"
   },
   "source": [
    "### GPU support\n",
    "\n",
    "A crucial feature of PyTorch is the support of GPUs, short for Graphics Processing Unit. A GPU can perform many thousands of small operations in parallel, making it very well suitable for performing large matrix operations in neural networks. When comparing GPUs to CPUs, we can list the following main differences (credit: [Kevin Krewell, 2009](https://blogs.nvidia.com/blog/2009/12/16/whats-the-difference-between-a-cpu-and-a-gpu/))\n",
    "\n",
    "GPUs can accelerate the training of your network up to a factor of $100$ which is essential for large neural networks. PyTorch implements a lot of functionality for supporting GPUs (mostly those of NVIDIA due to the libraries [CUDA](https://developer.nvidia.com/cuda-zone) and [cuDNN](https://developer.nvidia.com/cudnn)). First, let's check whether you have a GPU available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZxv7sYGlvLt",
    "outputId": "48a94d56-5a3c-44b1-c29f-9da0b9295f3a"
   },
   "outputs": [],
   "source": [
    "gpu_avail = torch.cuda.is_available()\n",
    "print(f\"Is the GPU available? {gpu_avail}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dT09bFt1lvLt",
    "outputId": "94cd67ee-eaa1-4e58-82a0-8e6d063a315e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") # or cuda:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JafnEUSClvLt"
   },
   "source": [
    "Now let's create a tensor and push it to the device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndryPu8KlvLt",
    "outputId": "f1db733a-0b4e-4327-d40f-6b99230aa6fe"
   },
   "outputs": [],
   "source": [
    "x = torch.zeros(2, 3)\n",
    "x = x.to(device)\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l90i9PnNlvLu"
   },
   "source": [
    "PyTorch also supports multi-GPU systems, but this you will only need once you have very big networks to train (if interested, see the [PyTorch documentation](https://pytorch.org/docs/stable/distributed.html#distributed-basics))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Un0eIboLlvLu",
    "outputId": "9cc8878a-fa57-4834-af83-635a3e287951"
   },
   "outputs": [],
   "source": [
    "# We can also compare the runtime of a large matrix multiplication on the CPU with a operation on the GPU:\n",
    "\n",
    "x = torch.randn(5000, 5000)\n",
    "\n",
    "## CPU version\n",
    "start_time = time.time()\n",
    "_ = torch.matmul(x, x)\n",
    "end_time = time.time()\n",
    "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
    "\n",
    "## GPU version\n",
    "x = x.to(device)\n",
    "_ = torch.matmul(x, x)  # First operation to 'burn in' GPU\n",
    "# CUDA is asynchronous, so we need to use different timing functions\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "start.record()\n",
    "_ = torch.matmul(x, x)\n",
    "end.record()\n",
    "torch.cuda.synchronize()  # Waits for everything to finish running on the GPU\n",
    "print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\")  # Milliseconds to seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLJMjcWPlvLu"
   },
   "source": [
    "### Defining deep learning models\n",
    "\n",
    "The package `torch.nn` defines a series of useful classes like linear networks layers, activation functions, loss functions etc. A full list can be found [here](https://pytorch.org/docs/stable/nn.html).\n",
    "\n",
    "`torch.nn.functional` contains functions that are used in network layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "at0Vekp0lvLu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioq4TX6XlvLu"
   },
   "source": [
    "#### nn.Module\n",
    "\n",
    "In PyTorch, a neural network is built up out of modules. Modules can contain other modules, and a neural network is considered to be a module itself as well. The basic template of a module is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b10tUfNSlvLu"
   },
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Some init for my module\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Function for performing the calculation of the module.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDYTCX2MlvLu"
   },
   "source": [
    "The forward function is where the computation of the module is taken place, and is executed when you call the module (`nn = MyModule(); nn(x)`). In the init function, we usually create the parameters of the module, using `nn.Parameter`, or defining other modules that are used in the forward function. The backward calculation is done automatically, but could be overwritten as well if wanted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple classifier\n",
    "We can now make use of the pre-defined modules in the `torch.nn` package, and define our own small neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTVFW8EhlvLu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "        # Initialize the modules we need to build the network\n",
    "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(num_hidden, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Perform the calculation of the model to determine the prediction\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uY1ocCwplvLv",
    "outputId": "06cf844a-6c61-4660-bccd-6efc75284a4d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printing a module shows all its submodules\n",
    "model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueJR4_TMlvLv",
    "outputId": "1bd93d0e-a712-42fe-d4d5-99b608a2e3a2"
   },
   "outputs": [],
   "source": [
    "# The parameters of a module can be obtained by using its `parameters()` functions, or `named_parameters()\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter {name}, shape {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNdm-asklvLv"
   },
   "source": [
    "### The data\n",
    "\n",
    "PyTorch also provides a few functionalities to load the training and test data efficiently, summarized in the package `torch.utils.data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8t7VDifnlvLv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OENXh_JlvLv"
   },
   "source": [
    "The data package defines two classes which are the standard interface for handling data in PyTorch: `data.Dataset`, and `data.DataLoader`. The dataset class provides an uniform interface to access the training/test data, while the data loader makes sure to efficiently load and stack the data points from the dataset into batches during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXjOME5VlvLv"
   },
   "source": [
    "#### The dataset class\n",
    "To define a dataset in PyTorch, we simply specify two functions: `__getitem__`, and `__len__`. The get-item function has to return the $i$-th data point in the dataset, while the len function returns the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwglCtyylvLv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class RandomDataset(Dataset):\n",
    "    def __init__(self, size, num_features=2):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            size - Number of data points we want to generate\n",
    "            num_features - Number of features per data point\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.data = torch.randn(size, num_features)  # Random data points\n",
    "        self.label = torch.randint(0, 2, (size,))    # Random labels (0 or 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3llJSBSlvLv"
   },
   "source": [
    "Let's try to create such a dataset and inspect it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8VHg9jClvLv",
    "outputId": "1602b9a6-d336-47e8-c5eb-8fd481ba36dc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = RandomDataset(size=200, num_features = 2)\n",
    "print(\"Size of dataset:\", len(dataset))\n",
    "print(\"Data point 0:\", dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMk6ENqSlvLv"
   },
   "source": [
    "To better relate to the dataset, we visualize the samples below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4dpfJYflvLw"
   },
   "source": [
    "#### The data loader class\n",
    "\n",
    "The class `torch.utils.data.DataLoader` represents a Python iterable over a dataset with support for automatic batching, multi-process data loading and many more features. We can configure our data loader with input arguments: (only a selection, see full list [here](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)):\n",
    "\n",
    "* `batch_size`: Number of samples to stack per batch\n",
    "* `shuffle`: If True, the data is returned in a random order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqIwK4e7lvLw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_loader = data.DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "# For iterating over the whole dataset, we can simple use \"for batch in data_loader: ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIn1vzjRlvLw",
    "outputId": "29506b8d-95ae-4859-91a4-9024e883b666"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PkJkafBYlvLw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for binary classification, we can use Binary Cross Entropy (BCE) which is defined as follows:\n",
    "loss_module = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# For updating the parameters, PyTorch provides the package `torch.optim` that has most popular optimizers implemented.\n",
    "# Input to the optimizer are the parameters of the model: model.parameters()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Sk5rOR_lvLw"
   },
   "outputs": [],
   "source": [
    "# optimizer.step() updates the parameters based on the gradients\n",
    "# optimizer.zero_grad() clears any existing gradients from previous backward passes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tnL9dSylvLw"
   },
   "source": [
    "### Training\n",
    "\n",
    "Finally, we are ready to train our model. As a first step, we create a slightly larger dataset and specify a data loader with a larger batch size.\n",
    "\n",
    "During training, we will perform the following steps:\n",
    "\n",
    "1. Get a batch from the data loader\n",
    "2. Obtain the predictions from the model for the batch\n",
    "3. Calculate the loss based on the difference between predictions and labels\n",
    "4. Backpropagation: calculate the gradients for every parameter with respect to the loss\n",
    "5. Update the parameters of the model in the direction of the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "INB18WuFlvLw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = RandomDataset(size=2500)\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Push model to device. Has to be only done once\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIPhxLyDlvLw"
   },
   "source": [
    "In addition, we set our model to training mode. This is done by calling `model.train()`. There exist certain modules that need to perform a different forward step during training than during testing (e.g. BatchNorm and Dropout), and we can switch between them using `model.train()` and `model.eval()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQkGapUulvLw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, data_loader, loss_module, num_epochs=100):\n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Optional: print progress every few epochs\n",
    "        if (epoch + 1) % 10 == 0:  # prints every 10 epochs\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "            \n",
    "        for data_inputs, data_labels in data_loader:\n",
    "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
    "            data_inputs = data_inputs.to(device)\n",
    "            data_labels = data_labels.to(device)\n",
    "            ## Step 2: Run the model on the input data\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
    "            ## Step 3: Calculate the loss\n",
    "            loss = loss_module(preds, data_labels.float())\n",
    "            ## Step 4: Perform backpropagation\n",
    "            # Before calculating the gradients, we need to ensure that they are all zero.\n",
    "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
    "            optimizer.zero_grad()\n",
    "            # Perform backpropagation\n",
    "            loss.backward()\n",
    "            ## Step 5: Update the parameters\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "eb0f1646f5f4459c86c22f0845150144"
     ]
    },
    "id": "MG1_vATJlvLw",
    "outputId": "2c93adec-d4af-49c3-dd5a-549da6b1ae16",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_model(model, optimizer, train_data_loader, loss_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand on - exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will train a classification model on the CIFAR-10 dataset. CIFAR-10 is a widely used benchmark dataset in computer vision, primarily for image classification tasks. The dataset contains 60,000 images in 10 classes, with each class representing a distinct object category such as airplanes, cars, birds, cats, and dogs. Each image having a resolution of 32x32 pixels and three color channels (RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data as data\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    # Load CIFAR-10 dataset\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                          download=True, transform=transform)\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                         download=True, transform=transform)\n",
    "    \n",
    "    trainloader = data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "    testloader = data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "    \n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainloader, testloader = load_data()\n",
    "\n",
    "for images, labels in trainloader:\n",
    "    print(f\"Batch shape: {images.shape}\")\n",
    "    print(f\"Number of channels: {images.shape[1]}\")\n",
    "    print(f\"Image height: {images.shape[2]}\")\n",
    "    print(f\"Image width: {images.shape[3]}\")\n",
    "    break  # Just look at first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Instructions:\n",
    "1. Define a 3 layer CNN model (ConvNet) for multi-label classification with the following architecture:\n",
    "\n",
    "   - Input shape: [batch_size, 3, 32, 32]\n",
    "   \n",
    "   - **Convolutional Layers**:\n",
    "     - Conv Layer 1: \n",
    "       - `nn.Conv2d` with 32 output channels, kernel size of 3, padding of 1\n",
    "       - `nn.ReLU` activation\n",
    "       - `nn.MaxPool2d` with a 2x2 window\n",
    "     - Conv Layer 2: \n",
    "       - `nn.Conv2d` with 64 output channels, kernel size of 3, padding of 1\n",
    "       - `nn.ReLU` activation\n",
    "       - `nn.MaxPool2d` with a 2x2 window\n",
    "     - Conv Layer 3: \n",
    "       - `nn.Conv2d` with 128 output channels, kernel size of 3, padding of 1\n",
    "       - `nn.ReLU` activation\n",
    "       - `nn.MaxPool2d` with a 2x2 window \n",
    "       \n",
    "   - **Fully Connected (FC) Layers**:\n",
    "     - Flatten Layer:\n",
    "       - Use `nn.Flatten()` create a 2d tensor of shape [batch_size, embedding_size] \n",
    "     - FC Layer 1: \n",
    "       - `nn.Linear` with output size 512\n",
    "       - `nn.ReLU` activation\n",
    "       - `nn.Dropout` with probability 0.5\n",
    "     - Output Layer:\n",
    "       - `nn.Linear`for outputting the logits\n",
    "       \n",
    "       \n",
    "2. If required: experiment with any other multi-label classification model of your choice!:\n",
    "   - Try different layer configurations, activation functions, or number of filters.\n",
    "\n",
    "3. Train and evaluate the model on the CIFAR-10 dataset for multi-label classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # Code your convolutional layers here\n",
    "        self.conv_layers = nn.Sequential(\n",
    "\n",
    "        )\n",
    "        \n",
    "        # Code your fully connected layers here\n",
    "        self.fc_layers = nn.Sequential(\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through convolutional layers\n",
    "        x = self.conv_layers(x)\n",
    "        \n",
    "        # Pass through fully connected layers\n",
    "        x = self.fc_layers(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, num_epochs=10):\n",
    "    device = torch.device(\"cuda:0\") # change according to your config\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # what should the loss function be in this case?\n",
    "    loss_fn = None\n",
    "    \n",
    "    # use Adam optimizer \n",
    "    optimizer = None \n",
    "    \n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            \n",
    "            # Step 1: transfer the batch to the device\n",
    "            \n",
    "            # Step 2: cancel out any hanging gradients\n",
    "            \n",
    "            # Step 3: forward pass for the model\n",
    "            \n",
    "            # Step 4: calculate the loss \n",
    "          \n",
    "            # Step 5: backpropagation to calculate gradients\n",
    "          \n",
    "            # Step 6: update model parameters\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}], Loss: {running_loss/100:.4f}')\n",
    "                train_losses.append(running_loss/100)\n",
    "                running_loss = 0.0\n",
    "                \n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, testloader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = [0] * 10\n",
    "    class_total = [0] * 10\n",
    "    \n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Per-class accuracy\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "    \n",
    "    print(f'Overall Accuracy: {100 * correct / total:.2f}%')\n",
    "    print('\\nPer-class accuracy:')\n",
    "    for i in range(10):\n",
    "        print(f'{classes[i]}: {100 * class_correct[i] / class_total[i]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_results(train_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.title('Training Loss Over Time')\n",
    "    plt.xlabel('Iterations (x100)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = ConvNet()\n",
    "\n",
    "# Train model\n",
    "train_losses = train_model(model, trainloader)\n",
    "\n",
    "# Evaluate model\n",
    "evaluate_model(model, testloader)\n",
    "\n",
    "# Visualize results\n",
    "visualize_results(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can come back to this later or at the end of the course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a simplified Vision Transformer (ViT) model for CIFAR-10 Image Classification\n",
    "\n",
    "1. Use PyTorch `nn` functions to build each component of the ViT model.\n",
    "    - `nn.Conv2d` for the Patch Embedding.\n",
    "    - `nn.Parameter` for the Positional Encoding.\n",
    "    - `nn.Parameter` for adding CLS token\n",
    "    - `nn.TransformerEncoder` and `nn.TransformerEncoderLayer` for the Transformer Encoder.\n",
    "    - `nn.LayerNorm` and `nn.Linear` for the Classification Head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Transformer-based Vision Model\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, image_size=32, patch_size=4, num_classes=10, dim=256, depth=6, heads=8, mlp_dim=512):\n",
    "        super().__init__()\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        patch_dim = 3 * patch_size * patch_size\n",
    "\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "        ## Instantiate the following:\n",
    "        \n",
    "        # Patch embedding layer  \n",
    "        self.patch_embedding = None\n",
    "        \n",
    "        # Position embedding \n",
    "        self.pos_embedding = None\n",
    "        \n",
    "        # CLS token \n",
    "        self.cls_token = None\n",
    "        \n",
    "        # Transformer encoder\n",
    "\n",
    "        # MLP head\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        ### Apply the following tranformations to generate classification logits\n",
    "        # Split image into patches\n",
    "        \n",
    "        # Patch embedding\n",
    "        \n",
    "        # Add cls token\n",
    "\n",
    "        # Add position embedding\n",
    "        \n",
    "        # Apply transformer\n",
    "        \n",
    "        # Use cls token for classification\n",
    "        \n",
    "        # MLP head\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = VisionTransformer()\n",
    "\n",
    "# Train model\n",
    "train_losses = train_model(model, trainloader)\n",
    "\n",
    "# Evaluate model\n",
    "evaluate_model(model, testloader)\n",
    "\n",
    "# Visualize results\n",
    "visualize_results(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
