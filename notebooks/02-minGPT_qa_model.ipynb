{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093ee937-f65f-4ef7-b175-2fffc165b371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_dataset_builder, get_dataset_split_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c33e4-d23b-44ee-a8f0-3ece5aa34489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_NAME = \"bigbio/med_qa\"\n",
    "DATASET_CONFIG = \"med_qa_en_source\"\n",
    "ds_builder = load_dataset_builder(DATASET_NAME,DATASET_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bcd705-f928-4b5a-84b3-f7775b4067e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(ds_builder.info.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a06609-a5cd-40f1-a36e-0977e58c9c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = load_dataset(DATASET_NAME, DATASET_CONFIG, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c891ee17-01cd-4092-bc74-d5717d114740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52eb84a-2792-498a-af66-fa442fc94e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mingpt.bpe import BPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d705118-7984-4bac-864c-23976355e1c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bpe_tokenizer = BPETokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dae492-65f2-4bed-a14a-a17f59e8989d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bpe_tokenizer(train_ds[0]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12118bd-a9ef-4735-9be5-ab153cc74bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = bpe_tokenizer.encoder.encode_and_show_work(train_ds[0]['question'])\n",
    "# print(train_ds[0]['question'])\n",
    "for a in results['parts']:\n",
    "    print(a['token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9105b35-b65b-44ca-84e2-03005d89e021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_examples(example):\n",
    "    training_sentence = f\"{example['question']}\\nAnswer: {example['answer']}\\n\"\n",
    "    return bpe_tokenizer(training_sentence)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdab74b-cd96-4b22-9902-03c49d951927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer_examples = [encode_examples(ex) for ex in train_ds]\n",
    "\n",
    "# I only want to keep examples longer than 128 tokens\n",
    "# I only want to use the last 129 tokens of each example\n",
    "tokenized_train = [ex[-129:] for ex in tokenizer_examples if len(ex) >= 129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ce216-7355-4cdc-846b-bb2105c94685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SimpleMedQADataset(Dataset):\n",
    "    def __init__(self, tokenized_examples):\n",
    "        self.tokenized_examples = tokenized_examples\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_examples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokenized_examples[idx][:-1], self.tokenized_examples[idx][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6738c2-942c-45b1-b0c1-1e8f4a3ed677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = SimpleMedQADataset(tokenized_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d304f-63e7-48d3-a0d3-66408672129f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mingpt.model import GPT\n",
    "\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.model_type = 'gpt2'\n",
    "model_config.vocab_size = 50257\n",
    "model_config.block_size = 256\n",
    "model = GPT(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2077549-07e7-4d11-8063-b69080a0a215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mingpt.trainer import Trainer\n",
    "\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 5e-4 # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 2000\n",
    "train_config.num_workers = 0\n",
    "trainer = Trainer(train_config, model, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282c1305-1d8b-4788-8417-41f207f3e758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch_end_callback(trainer):\n",
    "    if trainer.iter_num % 10 == 0:\n",
    "        print(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
    "trainer.set_callback('on_batch_end', batch_end_callback)\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51584155-f5fb-42e2-a05d-14f1e6755bb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 5\n",
    "\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "inputs = bpe_tokenizer(train_ds[idx]['question']+\"\\nAnswer: \").to(device)\n",
    "outputs = model.generate(inputs, max_new_tokens=20, temperature=1.2, top_k=40, do_sample=True)\n",
    "\n",
    "try:\n",
    "    offset = list(outputs[0][-20:]).index(198)\n",
    "except:\n",
    "    offset = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcceb9bb-e863-4ee5-be4b-858c5583bbc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_ds[idx]['question'])\n",
    "bpe_tokenizer.decode(outputs[0][len(inputs[0]):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6f7854-84fd-47f4-9424-c8089d1f53ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds[idx]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a1101-5fda-4d67-86ce-b14586033c4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bpe_tokenizer(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5189b175-ab8d-475f-8ec0-d5440cffd53f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
